{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8ced29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import Dict, Iterable, Tuple, Optional\n",
    "from conllu import parse_incr, TokenList\n",
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "def _rebuild_text_and_offsets(tokens: Iterable[dict]) -> Tuple[str, list[Tuple[int, int]]]:\n",
    "    \"\"\"\n",
    "    Rebuilds the original sentence text from FORM fields, respecting the 'SpaceAfter=No' rule.\n",
    "    At the same time, calculates the (start, end) character offsets for each token in the reconstructed string.\n",
    "\n",
    "    Parameters:\n",
    "        tokens (Iterable[dict]): List of token dictionaries from a UD-parsed sentence.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[str, list[Tuple[int, int]]]: \n",
    "            - The reconstructed sentence text.\n",
    "            - A list of (start, end) character offsets for each token.\n",
    "    \"\"\"\n",
    "    parts = []   # will store all text fragments\n",
    "    spans = []   # will store the (start, end) offsets for each token\n",
    "    cursor = 0   # keeps track of the current position in the reconstructed text\n",
    "\n",
    "    for tok in tokens:\n",
    "        form = tok[\"form\"]\n",
    "        misc = tok.get(\"misc\") or {}\n",
    "\n",
    "        # Check if we need to insert a space before this token\n",
    "        # Only insert if there is a previous token and no 'SpaceAfter=No' from the previous token\n",
    "        if parts and parts[-1] != \"\" and spans:\n",
    "            prev_no_space = tok.get(\"_prev_no_space\", False)\n",
    "        else:\n",
    "            prev_no_space = False\n",
    "\n",
    "        if parts and not prev_no_space:\n",
    "            parts.append(\" \")\n",
    "            cursor += 1\n",
    "\n",
    "        # Store token start and end positions\n",
    "        start = cursor\n",
    "        parts.append(form)\n",
    "        cursor += len(form)\n",
    "        end = cursor\n",
    "        spans.append((start, end))\n",
    "\n",
    "        # Mark whether this token should NOT have space after it\n",
    "        tok[\"_this_no_space\"] = (misc.get(\"SpaceAfter\") == \"No\")\n",
    "\n",
    "    # Second pass: propagate '_this_no_space' info to '_prev_no_space' of the next token\n",
    "    for i in range(1, len(spans)):\n",
    "        tokens[i][\"_prev_no_space\"] = tokens[i-1].get(\"_this_no_space\", False)\n",
    "\n",
    "    text = \"\".join(parts)\n",
    "    return text, spans\n",
    "\n",
    "\n",
    "def read_ud_conllu(path: str | Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads a Universal Dependencies (UD) *.conllu file and returns a tidy DataFrame with gold annotations.\n",
    "    Ignores:\n",
    "      - Multiword tokens (IDs like '3-4')\n",
    "      - Empty nodes (IDs like '2.1')\n",
    "\n",
    "    Parameters:\n",
    "        path (str | Path): Path to the .conllu file.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing token-level annotations with character offsets.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        for sent in parse_incr(f):  # type: TokenList\n",
    "            # Get sentence ID from metadata\n",
    "            sent_id = (sent.metadata or {}).get(\"sent_id\") \\\n",
    "                      or (sent.metadata or {}).get(\"sentid\") \\\n",
    "                      or \"\"\n",
    "\n",
    "            # Keep only real tokens (integer IDs)\n",
    "            ud_tokens = [t for t in sent if isinstance(t[\"id\"], int)]\n",
    "\n",
    "            # If the sentence text is explicitly provided in metadata, use it\n",
    "            text_from_meta = (sent.metadata or {}).get(\"text\")\n",
    "            if text_from_meta:\n",
    "                text = text_from_meta\n",
    "                spans = []\n",
    "                cursor = 0\n",
    "                # Greedy alignment: match each token form sequentially in the text\n",
    "                for t in ud_tokens:\n",
    "                    form = t[\"form\"]\n",
    "                    pos = text.find(form, cursor)\n",
    "                    if pos < 0:\n",
    "                        # If not found, fallback to immediate position\n",
    "                        pos = cursor\n",
    "                    start = pos\n",
    "                    end = pos + len(form)\n",
    "                    spans.append((start, end))\n",
    "                    cursor = end\n",
    "            else:\n",
    "                # If no text metadata is present, reconstruct text manually\n",
    "                text, spans = _rebuild_text_and_offsets(ud_tokens)\n",
    "\n",
    "            # Add each token’s details to the row list\n",
    "            for (t, (start, end)) in zip(ud_tokens, spans):\n",
    "                feats: Optional[Dict[str, str]] = t.get(\"feats\") or {}\n",
    "                if isinstance(feats, str):\n",
    "                    # Sometimes feats are given as a string, so parse them into a dictionary\n",
    "                    d = {}\n",
    "                    for kv in feats.split(\"|\"):\n",
    "                        if \"=\" in kv:\n",
    "                            k, v = kv.split(\"=\", 1)\n",
    "                            d[k] = v\n",
    "                    feats = d\n",
    "\n",
    "                tense = feats.get(\"Tense\")\n",
    "\n",
    "                rows.append({\n",
    "                    \"sent_id\": sent_id,\n",
    "                    \"text\": text,\n",
    "                    \"token_id\": t[\"id\"],\n",
    "                    \"form\": t[\"form\"],\n",
    "                    \"lemma\": t.get(\"lemma\"),\n",
    "                    \"gold_upos\": t.get(\"upos\"),\n",
    "                    \"gold_xpos\": t.get(\"xpos\"),\n",
    "                    \"gold_feats\": feats,\n",
    "                    \"gold_tense\": tense,\n",
    "                    \"head\": t.get(\"head\"),\n",
    "                    \"deprel\": t.get(\"deprel\"),\n",
    "                    \"space_after\": not ((t.get(\"misc\") or {}).get(\"SpaceAfter\") == \"No\"),\n",
    "                    \"char_start\": start,\n",
    "                    \"char_end\": end,\n",
    "                    # Slots for future parser predictions\n",
    "                    \"spacy_upos\": None,\n",
    "                    \"spacy_feats\": None,\n",
    "                    \"spacy_tense\": None,\n",
    "                    \"stanza_upos\": None,\n",
    "                    \"stanza_feats\": None,\n",
    "                    \"stanza_tense\": None,\n",
    "                })\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # Convert certain columns to category for efficiency\n",
    "    for c in [\"gold_upos\", \"gold_tense\"]:\n",
    "        df[c] = df[c].astype(\"category\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec9ad6c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>text</th>\n",
       "      <th>token_id</th>\n",
       "      <th>form</th>\n",
       "      <th>lemma</th>\n",
       "      <th>gold_upos</th>\n",
       "      <th>gold_xpos</th>\n",
       "      <th>gold_feats</th>\n",
       "      <th>gold_tense</th>\n",
       "      <th>head</th>\n",
       "      <th>deprel</th>\n",
       "      <th>space_after</th>\n",
       "      <th>char_start</th>\n",
       "      <th>char_end</th>\n",
       "      <th>spacy_upos</th>\n",
       "      <th>spacy_feats</th>\n",
       "      <th>spacy_tense</th>\n",
       "      <th>stanza_upos</th>\n",
       "      <th>stanza_feats</th>\n",
       "      <th>stanza_tense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ParlaMint-UA_2022-01-25-m0.u90.p4.lang1.s2</td>\n",
       "      <td>Я коли вам кажу завжди про економіку, я дивлюс...</td>\n",
       "      <td>1</td>\n",
       "      <td>Я</td>\n",
       "      <td>я</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRON</td>\n",
       "      <td>{'Animacy': 'Anim', 'Case': 'Nom', 'Number': '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>nsubj:outer</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ParlaMint-UA_2022-01-25-m0.u90.p4.lang1.s2</td>\n",
       "      <td>Я коли вам кажу завжди про економіку, я дивлюс...</td>\n",
       "      <td>2</td>\n",
       "      <td>коли</td>\n",
       "      <td>коли</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>ADV</td>\n",
       "      <td>{'PronType': 'Rel'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>mark</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ParlaMint-UA_2022-01-25-m0.u90.p4.lang1.s2</td>\n",
       "      <td>Я коли вам кажу завжди про економіку, я дивлюс...</td>\n",
       "      <td>3</td>\n",
       "      <td>вам</td>\n",
       "      <td>ви</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRON</td>\n",
       "      <td>{'Animacy': 'Anim', 'Case': 'Dat', 'Number': '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>iobj</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ParlaMint-UA_2022-01-25-m0.u90.p4.lang1.s2</td>\n",
       "      <td>Я коли вам кажу завжди про економіку, я дивлюс...</td>\n",
       "      <td>4</td>\n",
       "      <td>кажу</td>\n",
       "      <td>казати</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VERB</td>\n",
       "      <td>{'Aspect': 'Imp', 'Mood': 'Ind', 'Number': 'Si...</td>\n",
       "      <td>Pres</td>\n",
       "      <td>10</td>\n",
       "      <td>advcl</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ParlaMint-UA_2022-01-25-m0.u90.p4.lang1.s2</td>\n",
       "      <td>Я коли вам кажу завжди про економіку, я дивлюс...</td>\n",
       "      <td>5</td>\n",
       "      <td>завжди</td>\n",
       "      <td>завжди</td>\n",
       "      <td>ADV</td>\n",
       "      <td>ADV</td>\n",
       "      <td>{'PronType': 'Tot'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>advmod</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      sent_id  \\\n",
       "0  ParlaMint-UA_2022-01-25-m0.u90.p4.lang1.s2   \n",
       "1  ParlaMint-UA_2022-01-25-m0.u90.p4.lang1.s2   \n",
       "2  ParlaMint-UA_2022-01-25-m0.u90.p4.lang1.s2   \n",
       "3  ParlaMint-UA_2022-01-25-m0.u90.p4.lang1.s2   \n",
       "4  ParlaMint-UA_2022-01-25-m0.u90.p4.lang1.s2   \n",
       "\n",
       "                                                text  token_id    form  \\\n",
       "0  Я коли вам кажу завжди про економіку, я дивлюс...         1       Я   \n",
       "1  Я коли вам кажу завжди про економіку, я дивлюс...         2    коли   \n",
       "2  Я коли вам кажу завжди про економіку, я дивлюс...         3     вам   \n",
       "3  Я коли вам кажу завжди про економіку, я дивлюс...         4    кажу   \n",
       "4  Я коли вам кажу завжди про економіку, я дивлюс...         5  завжди   \n",
       "\n",
       "    lemma gold_upos gold_xpos  \\\n",
       "0       я      PRON      PRON   \n",
       "1    коли     SCONJ       ADV   \n",
       "2      ви      PRON      PRON   \n",
       "3  казати      VERB      VERB   \n",
       "4  завжди       ADV       ADV   \n",
       "\n",
       "                                          gold_feats gold_tense  head  \\\n",
       "0  {'Animacy': 'Anim', 'Case': 'Nom', 'Number': '...        NaN    10   \n",
       "1                                {'PronType': 'Rel'}        NaN     4   \n",
       "2  {'Animacy': 'Anim', 'Case': 'Dat', 'Number': '...        NaN     4   \n",
       "3  {'Aspect': 'Imp', 'Mood': 'Ind', 'Number': 'Si...       Pres    10   \n",
       "4                                {'PronType': 'Tot'}        NaN     4   \n",
       "\n",
       "        deprel  space_after  char_start  char_end spacy_upos spacy_feats  \\\n",
       "0  nsubj:outer         True           0         1       None        None   \n",
       "1         mark         True           2         6       None        None   \n",
       "2         iobj         True           7        10       None        None   \n",
       "3        advcl         True          11        15       None        None   \n",
       "4       advmod         True          16        22       None        None   \n",
       "\n",
       "  spacy_tense stanza_upos stanza_feats stanza_tense  \n",
       "0        None        None         None         None  \n",
       "1        None        None         None         None  \n",
       "2        None        None         None         None  \n",
       "3        None        None         None         None  \n",
       "4        None        None         None         None  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_ud_conllu(\"data/uk_parlamint-ud-dev.conllu\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1a846f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Metrics (macro-F1) ---\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "from typing import List, Dict, Tuple, Optional, Iterable\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "def macro_f1(df: pd.DataFrame, y_col_true: str, y_col_pred: str,\n",
    "             labels: Optional[Iterable[str]] = None) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the macro-averaged F1 score for classification results.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing true and predicted labels.\n",
    "        y_col_true (str): Column name for true labels.\n",
    "        y_col_pred (str): Column name for predicted labels.\n",
    "        labels (Optional[Iterable[str]]): Set of labels to consider.\n",
    "            If None, all unique labels from both columns are used.\n",
    "\n",
    "    Returns:\n",
    "        float: Macro-averaged F1 score (0–1 range).\n",
    "    \"\"\"\n",
    "    y_true = df[y_col_true].astype(str)\n",
    "    y_pred = df[y_col_pred].astype(str)\n",
    "    if labels is None:\n",
    "        labels = sorted(set(y_true.unique()) | set(y_pred.unique()))\n",
    "    return f1_score(y_true, y_pred, labels=labels, average=\"macro\", zero_division=0)\n",
    "\n",
    "\n",
    "def macro_f1_tense(df: pd.DataFrame, pred_col: str, restrict_to_verbs: bool = True) -> float:\n",
    "    \"\"\"\n",
    "    Calculate macro-F1 for tense prediction.\n",
    "    Can optionally restrict evaluation to only verbs (gold_upos == 'VERB').\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame with gold and predicted tenses.\n",
    "        pred_col (str): Column containing predicted tenses.\n",
    "        restrict_to_verbs (bool): If True, only evaluate on verbs.\n",
    "\n",
    "    Returns:\n",
    "        float: Macro-averaged F1 score for tense prediction.\n",
    "    \"\"\"\n",
    "    data = df\n",
    "    if restrict_to_verbs:\n",
    "        data = data[data[\"gold_upos\"] == \"VERB\"]\n",
    "\n",
    "    def norm(series: pd.Series) -> pd.Series:\n",
    "        # Normalize to strings, replacing missing values with 'None'\n",
    "        if pd.api.types.is_categorical_dtype(series):\n",
    "            series = series.cat.add_categories([\"None\"]).fillna(\"None\")\n",
    "        else:\n",
    "            series = series.fillna(\"None\").astype(str)\n",
    "        return series.astype(str)\n",
    "\n",
    "    y_true = norm(data[\"gold_tense\"])\n",
    "    y_pred = norm(data[pred_col])\n",
    "\n",
    "    labels = sorted(set(y_true.unique()) | set(y_pred.unique()))\n",
    "    return f1_score(y_true, y_pred, labels=labels, average=\"macro\", zero_division=0)\n",
    "\n",
    "\n",
    "# --- Character-level alignment helpers ---\n",
    "def span_overlap(a: Tuple[int, int], b: Tuple[int, int]) -> int:\n",
    "    \"\"\"\n",
    "    Compute the number of overlapping characters between two spans.\n",
    "\n",
    "    Parameters:\n",
    "        a, b (Tuple[int, int]): (start, end) character indices.\n",
    "\n",
    "    Returns:\n",
    "        int: Number of overlapping characters (0 if none).\n",
    "    \"\"\"\n",
    "    return max(0, min(a[1], b[1]) - max(a[0], b[0]))\n",
    "\n",
    "\n",
    "def align_by_spans(ud_spans: List[Tuple[int, int]], pred_spans: List[Tuple[int, int]]) -> Dict[int, List[int]]:\n",
    "    \"\"\"\n",
    "    Align UD tokens with model-predicted tokens based on character span overlap.\n",
    "\n",
    "    Any non-zero overlap counts as a match.\n",
    "\n",
    "    Parameters:\n",
    "        ud_spans (List[Tuple[int, int]]): Character spans for UD tokens.\n",
    "        pred_spans (List[Tuple[int, int]]): Character spans for predicted tokens.\n",
    "\n",
    "    Returns:\n",
    "        Dict[int, List[int]]: Mapping from UD token index to a list of predicted token indices.\n",
    "    \"\"\"\n",
    "    mapping = defaultdict(list)\n",
    "    for i, u in enumerate(ud_spans):\n",
    "        for j, p in enumerate(pred_spans):\n",
    "            if span_overlap(u, p) > 0:\n",
    "                mapping[i].append(j)\n",
    "    return mapping\n",
    "\n",
    "\n",
    "# --- Run spaCy model and attach predictions ---\n",
    "def run_spacy_and_attach(df: pd.DataFrame, model_name: str = \"uk_core_news_md\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Run a spaCy model on the sentence texts in a UD DataFrame and attach UPOS and Tense predictions.\n",
    "\n",
    "    The function:\n",
    "      - Tokenizes each sentence with spaCy\n",
    "      - Aligns spaCy tokens to UD tokens using character spans\n",
    "      - Aggregates predictions for UD tokens that align with multiple model tokens\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): UD DataFrame containing columns: sent_id, text, char_start, char_end.\n",
    "        model_name (str): Name of the spaCy model to load.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Copy of the original DataFrame with `spacy_upos` and `spacy_tense` columns filled.\n",
    "    \"\"\"\n",
    "    nlp = spacy.load(model_name, disable=[])  # Use full pipeline: tokenization, POS, morph\n",
    "    out = df.copy()\n",
    "\n",
    "    # Process each sentence separately\n",
    "    for sent_id, seg in out.groupby(\"sent_id\", sort=False):\n",
    "        text = seg[\"text\"].iloc[0]\n",
    "        doc = nlp(text)\n",
    "\n",
    "        # Extract spaCy token spans and features\n",
    "        pred_spans = [(t.idx, t.idx + len(t.text)) for t in doc]\n",
    "        pred_upos = [t.pos_ for t in doc]\n",
    "        pred_tense = [t.morph.get(\"Tense\", [None])[0] if t.morph.get(\"Tense\") else None for t in doc]\n",
    "\n",
    "        # UD token spans (in order)\n",
    "        ud_spans = list(zip(seg[\"char_start\"].tolist(), seg[\"char_end\"].tolist()))\n",
    "        mapping = align_by_spans(ud_spans, pred_spans)\n",
    "\n",
    "        # Aggregate predictions for each UD token\n",
    "        agg_upos, agg_tense = [], []\n",
    "        for i_ud in range(len(ud_spans)):\n",
    "            js = mapping.get(i_ud, [])\n",
    "            if not js:\n",
    "                agg_upos.append(None)\n",
    "                agg_tense.append(None)\n",
    "                continue\n",
    "\n",
    "            # Majority vote for UPOS\n",
    "            maj_upos = Counter(pred_upos[j] for j in js if pred_upos[j] is not None).most_common(1)\n",
    "            pick_upos = maj_upos[0][0] if maj_upos else None\n",
    "\n",
    "            # Majority vote for Tense (pick first if multiple ties)\n",
    "            tens = [pred_tense[j] for j in js if pred_tense[j] not in (None, \"\")]\n",
    "            if tens:\n",
    "                pick_tense = Counter(tens).most_common(1)[0][0]\n",
    "            else:\n",
    "                pick_tense = None\n",
    "\n",
    "            agg_upos.append(pick_upos)\n",
    "            agg_tense.append(pick_tense)\n",
    "\n",
    "        # Write predictions back to the DataFrame\n",
    "        out.loc[seg.index, \"spacy_upos\"] = agg_upos\n",
    "        out.loc[seg.index, \"spacy_tense\"] = agg_tense\n",
    "\n",
    "    # Convert to categorical for efficiency\n",
    "    out[\"spacy_upos\"] = out[\"spacy_upos\"].astype(\"category\")\n",
    "    out[\"spacy_tense\"] = out[\"spacy_tense\"].astype(\"category\")\n",
    "    return out\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def run_stanza_and_attach(df, nlp=None):\n",
    "    import stanza\n",
    "    if nlp is None:\n",
    "        stanza.download(\"uk\")\n",
    "        nlp = stanza.Pipeline(\"uk\", processors=\"tokenize,mwt,pos,lemma\")\n",
    "\n",
    "    out = df.copy()\n",
    "\n",
    "    for sent_id, seg in out.groupby(\"sent_id\", sort=False):\n",
    "        text = seg[\"text\"].iloc[0]\n",
    "        doc = nlp(text)\n",
    "\n",
    "        pred_spans, pred_upos, pred_tense = [], [], []\n",
    "\n",
    "        for sent in doc.sentences:\n",
    "            for tok in sent.tokens:\n",
    "                start, end = tok.start_char, tok.end_char\n",
    "                if start is None or end is None:\n",
    "                    continue\n",
    "\n",
    "                upos_list = [w.upos for w in tok.words if w.upos]\n",
    "                feats_dicts = []\n",
    "                for w in tok.words:\n",
    "                    if w.feats:\n",
    "                        feats = dict(kv.split(\"=\", 1) for kv in w.feats.split(\"|\") if \"=\" in kv)\n",
    "                        feats_dicts.append(feats)\n",
    "\n",
    "                upos = Counter(upos_list).most_common(1)[0][0] if upos_list else None\n",
    "                tenses = [fd.get(\"Tense\") for fd in feats_dicts if fd.get(\"Tense\")]\n",
    "                tense = Counter(tenses).most_common(1)[0][0] if tenses else None\n",
    "\n",
    "                pred_spans.append((start, end))\n",
    "                pred_upos.append(upos)\n",
    "                pred_tense.append(tense)\n",
    "\n",
    "        ud_spans = list(zip(seg[\"char_start\"].tolist(), seg[\"char_end\"].tolist()))\n",
    "\n",
    "        mapping = align_by_spans(ud_spans, pred_spans)\n",
    "\n",
    "        agg_upos, agg_tense = [], []\n",
    "        for i_ud in range(len(ud_spans)):\n",
    "            js = mapping.get(i_ud, [])\n",
    "            if not js:\n",
    "                agg_upos.append(None)\n",
    "                agg_tense.append(None)\n",
    "                continue\n",
    "            maj_upos = Counter(pred_upos[j] for j in js if pred_upos[j] is not None).most_common(1)\n",
    "            pick_upos = maj_upos[0][0] if maj_upos else None\n",
    "            tens = [pred_tense[j] for j in js if pred_tense[j] not in (None, \"\")]\n",
    "            pick_tense = Counter(tens).most_common(1)[0][0] if tens else None\n",
    "\n",
    "            agg_upos.append(pick_upos)\n",
    "            agg_tense.append(pick_tense)\n",
    "\n",
    "        out.loc[seg.index, \"stanza_upos\"] = agg_upos\n",
    "        out.loc[seg.index, \"stanza_tense\"] = agg_tense\n",
    "\n",
    "    out[\"stanza_upos\"] = out[\"stanza_upos\"].astype(\"category\")\n",
    "    out[\"stanza_tense\"] = out[\"stanza_tense\"].astype(\"category\")\n",
    "    return out\n",
    "\n",
    "# --- Validation helpers ---\n",
    "def validate_ud_df(df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Validate a UD DataFrame to ensure it has correct structure and no critical errors.\n",
    "\n",
    "    Checks:\n",
    "        - Required columns are present\n",
    "        - No duplicate (sent_id, token_id) pairs\n",
    "        - All spans are valid (start < end and start >= 0)\n",
    "        - All sentences have non-empty text\n",
    "\n",
    "    Raises:\n",
    "        AssertionError: If any of the checks fail.\n",
    "    \"\"\"\n",
    "    # Check required columns\n",
    "    assert {\"sent_id\", \"text\", \"token_id\", \"gold_upos\", \"char_start\", \"char_end\"}.issubset(df.columns)\n",
    "\n",
    "    # Ensure (sent_id, token_id) is unique\n",
    "    assert df.duplicated([\"sent_id\", \"token_id\"]).sum() == 0, \"Duplicate (sent_id, token_id)\"\n",
    "\n",
    "    # Ensure all spans are valid\n",
    "    bad_spans = ((df[\"char_end\"] <= df[\"char_start\"]) | (df[\"char_start\"] < 0)).sum()\n",
    "    assert bad_spans == 0, f\"Invalid spans: {bad_spans}\"\n",
    "\n",
    "    # Ensure no sentence has empty text\n",
    "    assert (df.groupby(\"sent_id\")[\"text\"].first().str.len() == 0).sum() == 0, \"#text is empty\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7f66937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.8.7-cp311-cp311-macosx_11_0_arm64.whl.metadata (27 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Using cached spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.13-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.2 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading cymem-2.0.11-cp311-cp311-macosx_11_0_arm64.whl.metadata (8.5 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading preshed-3.0.10-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.4 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
      "  Downloading thinc-8.3.6-cp311-cp311-macosx_11_0_arm64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Using cached wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Downloading srsly-2.5.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (19 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Using cached catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
      "  Using cached weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /Users/pelmeshek1706/Desktop/projects/phd_311_venv/lib/python3.11/site-packages (from spacy) (0.15.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/pelmeshek1706/Desktop/projects/phd_311_venv/lib/python3.11/site-packages (from spacy) (4.67.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/pelmeshek1706/Desktop/projects/phd_311_venv/lib/python3.11/site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/pelmeshek1706/Desktop/projects/phd_311_venv/lib/python3.11/site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/pelmeshek1706/Desktop/projects/phd_311_venv/lib/python3.11/site-packages (from spacy) (2.10.6)\n",
      "Requirement already satisfied: jinja2 in /Users/pelmeshek1706/Desktop/projects/phd_311_venv/lib/python3.11/site-packages (from spacy) (3.1.5)\n",
      "Requirement already satisfied: setuptools in /Users/pelmeshek1706/Desktop/projects/phd_311_venv/lib/python3.11/site-packages (from spacy) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/pelmeshek1706/Desktop/projects/phd_311_venv/lib/python3.11/site-packages (from spacy) (24.2)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Using cached langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Using cached language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/pelmeshek1706/Desktop/projects/phd_311_venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/pelmeshek1706/Desktop/projects/phd_311_venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/pelmeshek1706/Desktop/projects/phd_311_venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/pelmeshek1706/Desktop/projects/phd_311_venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/pelmeshek1706/Desktop/projects/phd_311_venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/pelmeshek1706/Desktop/projects/phd_311_venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/pelmeshek1706/Desktop/projects/phd_311_venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
      "Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading blis-1.3.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.4 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Using cached confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting numpy>=1.19.0 (from spacy)\n",
      "  Downloading numpy-2.3.2-cp311-cp311-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click>=8.0.0 in /Users/pelmeshek1706/Desktop/projects/phd_311_venv/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/pelmeshek1706/Desktop/projects/phd_311_venv/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/pelmeshek1706/Desktop/projects/phd_311_venv/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading cloudpathlib-0.21.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading smart_open-7.3.0.post1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/pelmeshek1706/Desktop/projects/phd_311_venv/lib/python3.11/site-packages (from jinja2->spacy) (3.0.2)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Using cached marisa_trie-1.2.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/pelmeshek1706/Desktop/projects/phd_311_venv/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/pelmeshek1706/Desktop/projects/phd_311_venv/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\n",
      "Requirement already satisfied: wrapt in /Users/pelmeshek1706/Desktop/projects/phd_311_venv/lib/python3.11/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/pelmeshek1706/Desktop/projects/phd_311_venv/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Downloading spacy-3.8.7-cp311-cp311-macosx_11_0_arm64.whl (6.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.11-cp311-cp311-macosx_11_0_arm64.whl (41 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Downloading murmurhash-1.0.13-cp311-cp311-macosx_11_0_arm64.whl (26 kB)\n",
      "Downloading preshed-3.0.10-cp311-cp311-macosx_11_0_arm64.whl (127 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Using cached spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.1-cp311-cp311-macosx_11_0_arm64.whl (634 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m634.4/634.4 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading thinc-8.3.6-cp311-cp311-macosx_11_0_arm64.whl (845 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m845.3/845.3 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.3.2-cp311-cp311-macosx_14_0_arm64.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Using cached weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Downloading blis-1.3.0-cp311-cp311-macosx_11_0_arm64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cloudpathlib-0.21.1-py3-none-any.whl (52 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Using cached language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "Downloading smart_open-7.3.0.post1-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached marisa_trie-1.2.1-cp311-cp311-macosx_11_0_arm64.whl (174 kB)\n",
      "Installing collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, smart-open, numpy, murmurhash, marisa-trie, cloudpathlib, catalogue, srsly, preshed, language-data, blis, langcodes, confection, weasel, thinc, spacy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "numba 0.61.0 requires numpy<2.2,>=1.24, but you have numpy 2.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed blis-1.3.0 catalogue-2.0.10 cloudpathlib-0.21.1 confection-0.1.5 cymem-2.0.11 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.2.1 murmurhash-1.0.13 numpy-2.3.2 preshed-3.0.10 smart-open-7.3.0.post1 spacy-3.8.7 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 thinc-8.3.6 wasabi-1.1.3 weasel-0.4.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting uk-core-news-md==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/uk_core_news_md-3.8.0/uk_core_news_md-3.8.0-py3-none-any.whl (69.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pymorphy3>=1.0.0 (from uk-core-news-md==3.8.0)\n",
      "  Downloading pymorphy3-2.0.4-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting pymorphy3-dicts-uk (from uk-core-news-md==3.8.0)\n",
      "  Using cached pymorphy3_dicts_uk-2.4.1.1.1663094765-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting dawg2-python>=0.8.0 (from pymorphy3>=1.0.0->uk-core-news-md==3.8.0)\n",
      "  Using cached dawg2_python-0.9.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting pymorphy3-dicts-ru (from pymorphy3>=1.0.0->uk-core-news-md==3.8.0)\n",
      "  Using cached pymorphy3_dicts_ru-2.4.417150.4580142-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Downloading pymorphy3-2.0.4-py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.1/54.1 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pymorphy3_dicts_uk-2.4.1.1.1663094765-py2.py3-none-any.whl (8.2 MB)\n",
      "Using cached dawg2_python-0.9.0-py3-none-any.whl (9.3 kB)\n",
      "Using cached pymorphy3_dicts_ru-2.4.417150.4580142-py2.py3-none-any.whl (8.4 MB)\n",
      "Installing collected packages: pymorphy3-dicts-uk, pymorphy3-dicts-ru, dawg2-python, pymorphy3, uk-core-news-md\n",
      "Successfully installed dawg2-python-0.9.0 pymorphy3-2.0.4 pymorphy3-dicts-ru-2.4.417150.4580142 pymorphy3-dicts-uk-2.4.1.1.1663094765 uk-core-news-md-3.8.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('uk_core_news_md')\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -U spacy\n",
    "!python -m spacy download uk_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a57c80dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stanza\n",
      "  Downloading stanza-1.10.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting emoji (from stanza)\n",
      "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: numpy in /Users/pelmeshek1706/Desktop/projects/phd_311_venv/lib/python3.11/site-packages (from stanza) (2.3.2)\n",
      "Requirement already satisfied: protobuf>=3.15.0 in /Users/pelmeshek1706/Desktop/projects/phd_311_venv/lib/python3.11/site-packages (from stanza) (5.29.3)\n",
      "Requirement already satisfied: requests in /Users/pelmeshek1706/Desktop/projects/phd_311_venv/lib/python3.11/site-packages (from stanza) (2.32.3)\n",
      "Requirement already satisfied: networkx in /Users/pelmeshek1706/Desktop/projects/phd_311_venv/lib/python3.11/site-packages (from stanza) (3.4.2)\n",
      "Requirement already satisfied: torch>=1.3.0 in /Users/pelmeshek1706/Desktop/projects/phd_311_venv/lib/python3.11/site-packages (from stanza) (2.9.0.dev20250706)\n",
      "Requirement already satisfied: tqdm in /Users/pelmeshek1706/Desktop/projects/phd_311_venv/lib/python3.11/site-packages (from stanza) (4.67.0)\n",
      "Requirement already satisfied: filelock in /Users/pelmeshek1706/Desktop/projects/phd_311_venv/lib/python3.11/site-packages (from torch>=1.3.0->stanza) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/pelmeshek1706/Desktop/projects/phd_311_venv/lib/python3.11/site-packages (from torch>=1.3.0->stanza) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/pelmeshek1706/Desktop/projects/phd_311_venv/lib/python3.11/site-packages (from torch>=1.3.0->stanza) (1.14.0)\n",
      "Requirement already satisfied: jinja2 in /Users/pelmeshek1706/Desktop/projects/phd_311_venv/lib/python3.11/site-packages (from torch>=1.3.0->stanza) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /Users/pelmeshek1706/Desktop/projects/phd_311_venv/lib/python3.11/site-packages (from torch>=1.3.0->stanza) (2024.12.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/pelmeshek1706/Desktop/projects/phd_311_venv/lib/python3.11/site-packages (from requests->stanza) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/pelmeshek1706/Desktop/projects/phd_311_venv/lib/python3.11/site-packages (from requests->stanza) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/pelmeshek1706/Desktop/projects/phd_311_venv/lib/python3.11/site-packages (from requests->stanza) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/pelmeshek1706/Desktop/projects/phd_311_venv/lib/python3.11/site-packages (from requests->stanza) (2025.1.31)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/pelmeshek1706/Desktop/projects/phd_311_venv/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=1.3.0->stanza) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/pelmeshek1706/Desktop/projects/phd_311_venv/lib/python3.11/site-packages (from jinja2->torch>=1.3.0->stanza) (3.0.2)\n",
      "Downloading stanza-1.10.1-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: emoji, stanza\n",
      "Successfully installed emoji-2.14.1 stanza-1.10.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c8a4ad42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcf469c36a634c9abb80cfef892e0256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-09 23:46:21 INFO: Downloaded file to /Users/pelmeshek1706/stanza_resources/resources.json\n",
      "2025-08-09 23:46:21 INFO: Downloading default packages for language: uk (Ukrainian) ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58b781d1ac9e49ab91b5a6ac105fea53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://huggingface.co/stanfordnlp/stanza-uk/resolve/v1.10.0/models/default.zip:   0%|          | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-09 23:46:33 INFO: Downloaded file to /Users/pelmeshek1706/stanza_resources/uk/default.zip\n",
      "2025-08-09 23:46:34 INFO: Finished downloading models and saved to /Users/pelmeshek1706/stanza_resources\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "stanza.download(\"uk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "51529d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_ud_conllu(\"data/uk_parlamint-ud-dev.conllu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e281f944",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_ud_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "338dcee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4947a797daf946639a87f6a75e1dfed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-09 23:49:46 INFO: Downloaded file to /Users/pelmeshek1706/stanza_resources/resources.json\n",
      "2025-08-09 23:49:46 INFO: Downloading default packages for language: uk (Ukrainian) ...\n",
      "2025-08-09 23:49:47 INFO: File exists: /Users/pelmeshek1706/stanza_resources/uk/default.zip\n",
      "2025-08-09 23:49:49 INFO: Finished downloading models and saved to /Users/pelmeshek1706/stanza_resources\n",
      "2025-08-09 23:49:49 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb3b2e11f0984ef6b1dce0919e565ab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-09 23:49:49 INFO: Downloaded file to /Users/pelmeshek1706/stanza_resources/resources.json\n",
      "2025-08-09 23:49:49 INFO: Loading these models for language: uk (Ukrainian):\n",
      "===========================\n",
      "| Processor | Package     |\n",
      "---------------------------\n",
      "| tokenize  | iu          |\n",
      "| mwt       | iu          |\n",
      "| pos       | iu_charlm   |\n",
      "| lemma     | iu_nocharlm |\n",
      "===========================\n",
      "\n",
      "2025-08-09 23:49:49 INFO: Using device: cpu\n",
      "2025-08-09 23:49:49 INFO: Loading: tokenize\n",
      "2025-08-09 23:49:49 INFO: Loading: mwt\n",
      "2025-08-09 23:49:49 INFO: Loading: pos\n",
      "2025-08-09 23:49:51 INFO: Loading: lemma\n",
      "2025-08-09 23:49:51 INFO: Done loading processors!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>text</th>\n",
       "      <th>token_id</th>\n",
       "      <th>form</th>\n",
       "      <th>lemma</th>\n",
       "      <th>gold_upos</th>\n",
       "      <th>gold_xpos</th>\n",
       "      <th>gold_feats</th>\n",
       "      <th>gold_tense</th>\n",
       "      <th>head</th>\n",
       "      <th>deprel</th>\n",
       "      <th>space_after</th>\n",
       "      <th>char_start</th>\n",
       "      <th>char_end</th>\n",
       "      <th>spacy_upos</th>\n",
       "      <th>spacy_feats</th>\n",
       "      <th>spacy_tense</th>\n",
       "      <th>stanza_upos</th>\n",
       "      <th>stanza_feats</th>\n",
       "      <th>stanza_tense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ParlaMint-UA_2022-01-25-m0.u90.p4.lang1.s2</td>\n",
       "      <td>Я коли вам кажу завжди про економіку, я дивлюс...</td>\n",
       "      <td>1</td>\n",
       "      <td>Я</td>\n",
       "      <td>я</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRON</td>\n",
       "      <td>{'Animacy': 'Anim', 'Case': 'Nom', 'Number': '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>nsubj:outer</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PRON</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PRON</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ParlaMint-UA_2022-01-25-m0.u90.p4.lang1.s2</td>\n",
       "      <td>Я коли вам кажу завжди про економіку, я дивлюс...</td>\n",
       "      <td>2</td>\n",
       "      <td>коли</td>\n",
       "      <td>коли</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>ADV</td>\n",
       "      <td>{'PronType': 'Rel'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>mark</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>ADV</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ADV</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ParlaMint-UA_2022-01-25-m0.u90.p4.lang1.s2</td>\n",
       "      <td>Я коли вам кажу завжди про економіку, я дивлюс...</td>\n",
       "      <td>3</td>\n",
       "      <td>вам</td>\n",
       "      <td>ви</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRON</td>\n",
       "      <td>{'Animacy': 'Anim', 'Case': 'Dat', 'Number': '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>iobj</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>PRON</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PRON</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ParlaMint-UA_2022-01-25-m0.u90.p4.lang1.s2</td>\n",
       "      <td>Я коли вам кажу завжди про економіку, я дивлюс...</td>\n",
       "      <td>4</td>\n",
       "      <td>кажу</td>\n",
       "      <td>казати</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VERB</td>\n",
       "      <td>{'Aspect': 'Imp', 'Mood': 'Ind', 'Number': 'Si...</td>\n",
       "      <td>Pres</td>\n",
       "      <td>10</td>\n",
       "      <td>advcl</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>VERB</td>\n",
       "      <td>None</td>\n",
       "      <td>Pres</td>\n",
       "      <td>VERB</td>\n",
       "      <td>None</td>\n",
       "      <td>Pres</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ParlaMint-UA_2022-01-25-m0.u90.p4.lang1.s2</td>\n",
       "      <td>Я коли вам кажу завжди про економіку, я дивлюс...</td>\n",
       "      <td>5</td>\n",
       "      <td>завжди</td>\n",
       "      <td>завжди</td>\n",
       "      <td>ADV</td>\n",
       "      <td>ADV</td>\n",
       "      <td>{'PronType': 'Tot'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>advmod</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>ADV</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ADV</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      sent_id  \\\n",
       "0  ParlaMint-UA_2022-01-25-m0.u90.p4.lang1.s2   \n",
       "1  ParlaMint-UA_2022-01-25-m0.u90.p4.lang1.s2   \n",
       "2  ParlaMint-UA_2022-01-25-m0.u90.p4.lang1.s2   \n",
       "3  ParlaMint-UA_2022-01-25-m0.u90.p4.lang1.s2   \n",
       "4  ParlaMint-UA_2022-01-25-m0.u90.p4.lang1.s2   \n",
       "\n",
       "                                                text  token_id    form  \\\n",
       "0  Я коли вам кажу завжди про економіку, я дивлюс...         1       Я   \n",
       "1  Я коли вам кажу завжди про економіку, я дивлюс...         2    коли   \n",
       "2  Я коли вам кажу завжди про економіку, я дивлюс...         3     вам   \n",
       "3  Я коли вам кажу завжди про економіку, я дивлюс...         4    кажу   \n",
       "4  Я коли вам кажу завжди про економіку, я дивлюс...         5  завжди   \n",
       "\n",
       "    lemma gold_upos gold_xpos  \\\n",
       "0       я      PRON      PRON   \n",
       "1    коли     SCONJ       ADV   \n",
       "2      ви      PRON      PRON   \n",
       "3  казати      VERB      VERB   \n",
       "4  завжди       ADV       ADV   \n",
       "\n",
       "                                          gold_feats gold_tense  head  \\\n",
       "0  {'Animacy': 'Anim', 'Case': 'Nom', 'Number': '...        NaN    10   \n",
       "1                                {'PronType': 'Rel'}        NaN     4   \n",
       "2  {'Animacy': 'Anim', 'Case': 'Dat', 'Number': '...        NaN     4   \n",
       "3  {'Aspect': 'Imp', 'Mood': 'Ind', 'Number': 'Si...       Pres    10   \n",
       "4                                {'PronType': 'Tot'}        NaN     4   \n",
       "\n",
       "        deprel  space_after  char_start  char_end spacy_upos spacy_feats  \\\n",
       "0  nsubj:outer         True           0         1       PRON        None   \n",
       "1         mark         True           2         6        ADV        None   \n",
       "2         iobj         True           7        10       PRON        None   \n",
       "3        advcl         True          11        15       VERB        None   \n",
       "4       advmod         True          16        22        ADV        None   \n",
       "\n",
       "  spacy_tense stanza_upos stanza_feats stanza_tense  \n",
       "0         NaN        PRON         None          NaN  \n",
       "1         NaN         ADV         None          NaN  \n",
       "2         NaN        PRON         None          NaN  \n",
       "3        Pres        VERB         None         Pres  \n",
       "4         NaN         ADV         None          NaN  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = run_spacy_and_attach(df, model_name=\"uk_core_news_md\")\n",
    "df = run_stanza_and_attach(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c1299e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_spacy_upos = macro_f1(df, \"gold_upos\", \"spacy_upos\", labels=upos10)\n",
    "f1_stanza_upos = macro_f1(df, \"gold_upos\", \"stanza_upos\", labels=upos10)\n",
    "gap = f1_stanza_upos - f1_spacy_upos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "07d7513d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy UPOS F1: 0.972\n",
      "Stanza UPOS F1: 0.975\n",
      "GAP: 0.285%\n"
     ]
    }
   ],
   "source": [
    "print(f\"spaCy UPOS F1: {f1_spacy_upos:.3f}\")\n",
    "print(f\"Stanza UPOS F1: {f1_stanza_upos:.3f}\")\n",
    "print(f\"GAP: {gap:.3%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5610641a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy Tense F1 (VERB only):   0.972\n",
      "Stanza Tense F1 (VERB only):  0.929\n",
      "Tense gap (VERB only):        -4.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zz/9j6cqjd91k7190vj479mr1jw0000gn/T/ipykernel_9536/2265161707.py:50: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(series):\n",
      "/var/folders/zz/9j6cqjd91k7190vj479mr1jw0000gn/T/ipykernel_9536/2265161707.py:50: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(series):\n",
      "/var/folders/zz/9j6cqjd91k7190vj479mr1jw0000gn/T/ipykernel_9536/2265161707.py:50: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(series):\n",
      "/var/folders/zz/9j6cqjd91k7190vj479mr1jw0000gn/T/ipykernel_9536/2265161707.py:50: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(series):\n"
     ]
    }
   ],
   "source": [
    "f1_spacy_tense_verbs  = macro_f1_tense(df, \"spacy_tense\",  restrict_to_verbs=True)\n",
    "f1_stanza_tense_verbs = macro_f1_tense(df, \"stanza_tense\", restrict_to_verbs=True)\n",
    "gap_tense_verbs = f1_stanza_tense_verbs - f1_spacy_tense_verbs\n",
    "\n",
    "print(f\"spaCy Tense F1 (VERB only):   {f1_spacy_tense_verbs:.3f}\")\n",
    "print(f\"Stanza Tense F1 (VERB only):  {f1_stanza_tense_verbs:.3f}\")\n",
    "print(f\"Tense gap (VERB only):        {gap_tense_verbs:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2955a9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy Tense F1 (has gold Tense):   0.981\n",
      "Stanza Tense F1 (has gold Tense):  0.706\n",
      "Tense gap (has gold Tense):        -27.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zz/9j6cqjd91k7190vj479mr1jw0000gn/T/ipykernel_9536/2265161707.py:50: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(series):\n",
      "/var/folders/zz/9j6cqjd91k7190vj479mr1jw0000gn/T/ipykernel_9536/2265161707.py:50: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(series):\n",
      "/var/folders/zz/9j6cqjd91k7190vj479mr1jw0000gn/T/ipykernel_9536/2265161707.py:50: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(series):\n",
      "/var/folders/zz/9j6cqjd91k7190vj479mr1jw0000gn/T/ipykernel_9536/2265161707.py:50: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(series):\n"
     ]
    }
   ],
   "source": [
    "mask_has_tense = df[\"gold_tense\"].notna()\n",
    "f1_spacy_tense_all  = macro_f1_tense(df[mask_has_tense], \"spacy_tense\",  restrict_to_verbs=False)\n",
    "f1_stanza_tense_all = macro_f1_tense(df[mask_has_tense], \"stanza_tense\", restrict_to_verbs=False)\n",
    "gap_tense_all = f1_stanza_tense_all - f1_spacy_tense_all\n",
    "\n",
    "print(f\"spaCy Tense F1 (has gold Tense):   {f1_spacy_tense_all:.3f}\")\n",
    "print(f\"Stanza Tense F1 (has gold Tense):  {f1_stanza_tense_all:.3f}\")\n",
    "print(f\"Tense gap (has gold Tense):        {gap_tense_all:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c1ca3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zz/9j6cqjd91k7190vj479mr1jw0000gn/T/ipykernel_9536/1244214729.py:24: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(series):\n",
      "/var/folders/zz/9j6cqjd91k7190vj479mr1jw0000gn/T/ipykernel_9536/1244214729.py:24: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(series):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.971756372227338"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_spacy_tense = macro_f1_tense(df, \"spacy_tense\", restrict_to_verbs=True)\n",
    "f1_spacy_tense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab56c3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.99      0.96      0.98      1062\n",
      "         ADP       0.99      1.00      1.00       929\n",
      "         ADV       0.94      0.97      0.95       536\n",
      "         AUX       0.97      0.93      0.95        99\n",
      "       CCONJ       0.98      0.98      0.98       320\n",
      "         DET       0.96      0.98      0.97       396\n",
      "        NOUN       0.98      1.00      0.99      2647\n",
      "        PRON       0.99      0.98      0.98       521\n",
      "       PROPN       0.97      0.92      0.94       455\n",
      "        VERB       0.99      1.00      0.99      1202\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      8167\n",
      "   macro avg       0.97      0.97      0.97      8167\n",
      "weighted avg       0.98      0.98      0.98      8167\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df[\"gold_upos\"].astype(str),\n",
    "                            df[\"spacy_upos\"].astype(str),\n",
    "                            labels=upos10, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123494d8",
   "metadata": {},
   "source": [
    "# Without local files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1354689c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "def read_ud_conllu(path_or_url: str | Path) -> pd.DataFrame:\n",
    "    if str(path_or_url).startswith(\"http\"):\n",
    "        r = requests.get(path_or_url)\n",
    "        r.raise_for_status()\n",
    "        file_obj = StringIO(r.text)\n",
    "    else:\n",
    "        file_obj = open(path_or_url, encoding=\"utf-8\")\n",
    "\n",
    "    rows = []\n",
    "    with file_obj as f:\n",
    "        for sent in parse_incr(f):\n",
    "            sent_id = (sent.metadata or {}).get(\"sent_id\") or (sent.metadata or {}).get(\"sentid\") or \"\"\n",
    "            ud_tokens = [t for t in sent if isinstance(t[\"id\"], int)]\n",
    "            text_from_meta = (sent.metadata or {}).get(\"text\")\n",
    "            if text_from_meta:\n",
    "                text = text_from_meta\n",
    "                spans = []\n",
    "                cursor = 0\n",
    "                for t in ud_tokens:\n",
    "                    form = t[\"form\"]\n",
    "                    pos = text.find(form, cursor)\n",
    "                    if pos < 0:\n",
    "                        pos = cursor\n",
    "                    start = pos\n",
    "                    end = pos + len(form)\n",
    "                    spans.append((start, end))\n",
    "                    cursor = end\n",
    "            else:\n",
    "                text, spans = _rebuild_text_and_offsets(ud_tokens)\n",
    "\n",
    "            for (t, (start, end)) in zip(ud_tokens, spans):\n",
    "                feats = t.get(\"feats\") or {}\n",
    "                if isinstance(feats, str):\n",
    "                    feats = dict(kv.split(\"=\", 1) for kv in feats.split(\"|\") if \"=\" in kv)\n",
    "                tense = feats.get(\"Tense\")\n",
    "\n",
    "                rows.append({\n",
    "                    \"sent_id\": sent_id,\n",
    "                    \"text\": text,\n",
    "                    \"token_id\": t[\"id\"],\n",
    "                    \"form\": t[\"form\"],\n",
    "                    \"lemma\": t.get(\"lemma\"),\n",
    "                    \"gold_upos\": t.get(\"upos\"),\n",
    "                    \"gold_xpos\": t.get(\"xpos\"),\n",
    "                    \"gold_feats\": feats,\n",
    "                    \"gold_tense\": tense,\n",
    "                    \"head\": t.get(\"head\"),\n",
    "                    \"deprel\": t.get(\"deprel\"),\n",
    "                    \"space_after\": not ((t.get(\"misc\") or {}).get(\"SpaceAfter\") == \"No\"),\n",
    "                    \"char_start\": start,\n",
    "                    \"char_end\": end,\n",
    "                    \"spacy_upos\": None,\n",
    "                    \"spacy_feats\": None,\n",
    "                    \"spacy_tense\": None,\n",
    "                    \"stanza_upos\": None,\n",
    "                    \"stanza_feats\": None,\n",
    "                    \"stanza_tense\": None,\n",
    "                })\n",
    "    df = pd.DataFrame(rows)\n",
    "    for c in [\"gold_upos\", \"gold_tense\"]:\n",
    "        df[c] = df[c].astype(\"category\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3d1ebd",
   "metadata": {},
   "source": [
    "## test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cbfeee70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>text</th>\n",
       "      <th>token_id</th>\n",
       "      <th>form</th>\n",
       "      <th>lemma</th>\n",
       "      <th>gold_upos</th>\n",
       "      <th>gold_xpos</th>\n",
       "      <th>gold_feats</th>\n",
       "      <th>gold_tense</th>\n",
       "      <th>head</th>\n",
       "      <th>deprel</th>\n",
       "      <th>space_after</th>\n",
       "      <th>char_start</th>\n",
       "      <th>char_end</th>\n",
       "      <th>spacy_upos</th>\n",
       "      <th>spacy_feats</th>\n",
       "      <th>spacy_tense</th>\n",
       "      <th>stanza_upos</th>\n",
       "      <th>stanza_feats</th>\n",
       "      <th>stanza_tense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ParlaMint-UA_2022-01-25-m0.u185.p3.lang1.s1</td>\n",
       "      <td>За - 116</td>\n",
       "      <td>1</td>\n",
       "      <td>За</td>\n",
       "      <td>за</td>\n",
       "      <td>ADP</td>\n",
       "      <td>ADP</td>\n",
       "      <td>{'Case': 'Acc'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ParlaMint-UA_2022-01-25-m0.u185.p3.lang1.s1</td>\n",
       "      <td>За - 116</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>punct</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ParlaMint-UA_2022-01-25-m0.u185.p3.lang1.s1</td>\n",
       "      <td>За - 116</td>\n",
       "      <td>3</td>\n",
       "      <td>116</td>\n",
       "      <td>116</td>\n",
       "      <td>NUM</td>\n",
       "      <td>NUM</td>\n",
       "      <td>{'Case': 'Nom', 'NumType': 'Card'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>orphan</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ParlaMint-UA_2022-01-25-m0.u185.p4.lang1.s1</td>\n",
       "      <td>Рішення не прийнято.</td>\n",
       "      <td>1</td>\n",
       "      <td>Рішення</td>\n",
       "      <td>рішення</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>{'Animacy': 'Inan', 'Case': 'Acc', 'Gender': '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>obj</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ParlaMint-UA_2022-01-25-m0.u185.p4.lang1.s1</td>\n",
       "      <td>Рішення не прийнято.</td>\n",
       "      <td>2</td>\n",
       "      <td>не</td>\n",
       "      <td>не</td>\n",
       "      <td>PART</td>\n",
       "      <td>PART</td>\n",
       "      <td>{'Polarity': 'Neg'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>advmod:neg</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       sent_id                  text  \\\n",
       "0  ParlaMint-UA_2022-01-25-m0.u185.p3.lang1.s1              За - 116   \n",
       "1  ParlaMint-UA_2022-01-25-m0.u185.p3.lang1.s1              За - 116   \n",
       "2  ParlaMint-UA_2022-01-25-m0.u185.p3.lang1.s1              За - 116   \n",
       "3  ParlaMint-UA_2022-01-25-m0.u185.p4.lang1.s1  Рішення не прийнято.   \n",
       "4  ParlaMint-UA_2022-01-25-m0.u185.p4.lang1.s1  Рішення не прийнято.   \n",
       "\n",
       "   token_id     form    lemma gold_upos gold_xpos  \\\n",
       "0         1       За       за       ADP       ADP   \n",
       "1         2        -        -     PUNCT     PUNCT   \n",
       "2         3      116      116       NUM       NUM   \n",
       "3         1  Рішення  рішення      NOUN      NOUN   \n",
       "4         2       не       не      PART      PART   \n",
       "\n",
       "                                          gold_feats gold_tense  head  \\\n",
       "0                                    {'Case': 'Acc'}        NaN     0   \n",
       "1                                                 {}        NaN     3   \n",
       "2                 {'Case': 'Nom', 'NumType': 'Card'}        NaN     1   \n",
       "3  {'Animacy': 'Inan', 'Case': 'Acc', 'Gender': '...        NaN     3   \n",
       "4                                {'Polarity': 'Neg'}        NaN     3   \n",
       "\n",
       "       deprel  space_after  char_start  char_end spacy_upos spacy_feats  \\\n",
       "0        root         True           0         2       None        None   \n",
       "1       punct         True           3         4       None        None   \n",
       "2      orphan         True           5         8       None        None   \n",
       "3         obj         True           0         7       None        None   \n",
       "4  advmod:neg         True           8        10       None        None   \n",
       "\n",
       "  spacy_tense stanza_upos stanza_feats stanza_tense  \n",
       "0        None        None         None         None  \n",
       "1        None        None         None         None  \n",
       "2        None        None         None         None  \n",
       "3        None        None         None         None  \n",
       "4        None        None         None         None  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/UniversalDependencies/UD_Ukrainian-ParlaMint/master/uk_parlamint-ud-test.conllu\"\n",
    "df = read_ud_conllu(url)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "05835780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "087da60d147f464aa38935db8fd5eae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-10 00:08:30 INFO: Downloaded file to /Users/pelmeshek1706/stanza_resources/resources.json\n",
      "2025-08-10 00:08:30 INFO: Downloading default packages for language: uk (Ukrainian) ...\n",
      "2025-08-10 00:08:30 INFO: File exists: /Users/pelmeshek1706/stanza_resources/uk/default.zip\n",
      "2025-08-10 00:08:32 INFO: Finished downloading models and saved to /Users/pelmeshek1706/stanza_resources\n",
      "2025-08-10 00:08:32 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fd59340750948029d69d3af5b27a05c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-10 00:08:32 INFO: Downloaded file to /Users/pelmeshek1706/stanza_resources/resources.json\n",
      "2025-08-10 00:08:33 INFO: Loading these models for language: uk (Ukrainian):\n",
      "===========================\n",
      "| Processor | Package     |\n",
      "---------------------------\n",
      "| tokenize  | iu          |\n",
      "| mwt       | iu          |\n",
      "| pos       | iu_charlm   |\n",
      "| lemma     | iu_nocharlm |\n",
      "===========================\n",
      "\n",
      "2025-08-10 00:08:33 INFO: Using device: cpu\n",
      "2025-08-10 00:08:33 INFO: Loading: tokenize\n",
      "2025-08-10 00:08:33 INFO: Loading: mwt\n",
      "2025-08-10 00:08:33 INFO: Loading: pos\n",
      "2025-08-10 00:08:34 INFO: Loading: lemma\n",
      "2025-08-10 00:08:34 INFO: Done loading processors!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>text</th>\n",
       "      <th>token_id</th>\n",
       "      <th>form</th>\n",
       "      <th>lemma</th>\n",
       "      <th>gold_upos</th>\n",
       "      <th>gold_xpos</th>\n",
       "      <th>gold_feats</th>\n",
       "      <th>gold_tense</th>\n",
       "      <th>head</th>\n",
       "      <th>deprel</th>\n",
       "      <th>space_after</th>\n",
       "      <th>char_start</th>\n",
       "      <th>char_end</th>\n",
       "      <th>spacy_upos</th>\n",
       "      <th>spacy_feats</th>\n",
       "      <th>spacy_tense</th>\n",
       "      <th>stanza_upos</th>\n",
       "      <th>stanza_feats</th>\n",
       "      <th>stanza_tense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ParlaMint-UA_2022-01-25-m0.u185.p3.lang1.s1</td>\n",
       "      <td>За - 116</td>\n",
       "      <td>1</td>\n",
       "      <td>За</td>\n",
       "      <td>за</td>\n",
       "      <td>ADP</td>\n",
       "      <td>ADP</td>\n",
       "      <td>{'Case': 'Acc'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>ADP</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ParlaMint-UA_2022-01-25-m0.u185.p3.lang1.s1</td>\n",
       "      <td>За - 116</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>punct</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ParlaMint-UA_2022-01-25-m0.u185.p3.lang1.s1</td>\n",
       "      <td>За - 116</td>\n",
       "      <td>3</td>\n",
       "      <td>116</td>\n",
       "      <td>116</td>\n",
       "      <td>NUM</td>\n",
       "      <td>NUM</td>\n",
       "      <td>{'Case': 'Nom', 'NumType': 'Card'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>orphan</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>NUM</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NUM</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ParlaMint-UA_2022-01-25-m0.u185.p4.lang1.s1</td>\n",
       "      <td>Рішення не прийнято.</td>\n",
       "      <td>1</td>\n",
       "      <td>Рішення</td>\n",
       "      <td>рішення</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>{'Animacy': 'Inan', 'Case': 'Acc', 'Gender': '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>obj</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ParlaMint-UA_2022-01-25-m0.u185.p4.lang1.s1</td>\n",
       "      <td>Рішення не прийнято.</td>\n",
       "      <td>2</td>\n",
       "      <td>не</td>\n",
       "      <td>не</td>\n",
       "      <td>PART</td>\n",
       "      <td>PART</td>\n",
       "      <td>{'Polarity': 'Neg'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>advmod:neg</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>PART</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PART</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       sent_id                  text  \\\n",
       "0  ParlaMint-UA_2022-01-25-m0.u185.p3.lang1.s1              За - 116   \n",
       "1  ParlaMint-UA_2022-01-25-m0.u185.p3.lang1.s1              За - 116   \n",
       "2  ParlaMint-UA_2022-01-25-m0.u185.p3.lang1.s1              За - 116   \n",
       "3  ParlaMint-UA_2022-01-25-m0.u185.p4.lang1.s1  Рішення не прийнято.   \n",
       "4  ParlaMint-UA_2022-01-25-m0.u185.p4.lang1.s1  Рішення не прийнято.   \n",
       "\n",
       "   token_id     form    lemma gold_upos gold_xpos  \\\n",
       "0         1       За       за       ADP       ADP   \n",
       "1         2        -        -     PUNCT     PUNCT   \n",
       "2         3      116      116       NUM       NUM   \n",
       "3         1  Рішення  рішення      NOUN      NOUN   \n",
       "4         2       не       не      PART      PART   \n",
       "\n",
       "                                          gold_feats gold_tense  head  \\\n",
       "0                                    {'Case': 'Acc'}        NaN     0   \n",
       "1                                                 {}        NaN     3   \n",
       "2                 {'Case': 'Nom', 'NumType': 'Card'}        NaN     1   \n",
       "3  {'Animacy': 'Inan', 'Case': 'Acc', 'Gender': '...        NaN     3   \n",
       "4                                {'Polarity': 'Neg'}        NaN     3   \n",
       "\n",
       "       deprel  space_after  char_start  char_end spacy_upos spacy_feats  \\\n",
       "0        root         True           0         2        ADP        None   \n",
       "1       punct         True           3         4      PUNCT        None   \n",
       "2      orphan         True           5         8        NUM        None   \n",
       "3         obj         True           0         7       NOUN        None   \n",
       "4  advmod:neg         True           8        10       PART        None   \n",
       "\n",
       "  spacy_tense stanza_upos stanza_feats stanza_tense  \n",
       "0         NaN         ADP         None          NaN  \n",
       "1         NaN       PUNCT         None          NaN  \n",
       "2         NaN         NUM         None          NaN  \n",
       "3         NaN        NOUN         None          NaN  \n",
       "4         NaN        PART         None          NaN  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = run_spacy_and_attach(df, model_name=\"uk_core_news_md\")\n",
    "df = run_stanza_and_attach(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5476b9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy UPOS F1: 0.973\n",
      "Stanza UPOS F1: 0.972\n",
      "GAP: -0.112%\n"
     ]
    }
   ],
   "source": [
    "upos10 = [\"ADJ\",\"ADP\",\"ADV\",\"AUX\",\"CCONJ\",\"DET\",\"NOUN\",\"PRON\",\"PROPN\",\"VERB\"]\n",
    "\n",
    "f1_spacy_upos = macro_f1(df, \"gold_upos\", \"spacy_upos\", labels=upos10)\n",
    "f1_stanza_upos = macro_f1(df, \"gold_upos\", \"stanza_upos\", labels=upos10)\n",
    "gap = f1_stanza_upos - f1_spacy_upos\n",
    "\n",
    "print(f\"spaCy UPOS F1: {f1_spacy_upos:.3f}\")\n",
    "print(f\"Stanza UPOS F1: {f1_stanza_upos:.3f}\")\n",
    "print(f\"GAP: {gap:.3%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "920d2198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy Tense F1 (VERB only):   0.959\n",
      "Stanza Tense F1 (VERB only):  0.926\n",
      "Tense gap (VERB only):        -3.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zz/9j6cqjd91k7190vj479mr1jw0000gn/T/ipykernel_9536/2265161707.py:50: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(series):\n",
      "/var/folders/zz/9j6cqjd91k7190vj479mr1jw0000gn/T/ipykernel_9536/2265161707.py:50: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(series):\n",
      "/var/folders/zz/9j6cqjd91k7190vj479mr1jw0000gn/T/ipykernel_9536/2265161707.py:50: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(series):\n",
      "/var/folders/zz/9j6cqjd91k7190vj479mr1jw0000gn/T/ipykernel_9536/2265161707.py:50: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(series):\n"
     ]
    }
   ],
   "source": [
    "f1_spacy_tense_verbs  = macro_f1_tense(df, \"spacy_tense\",  restrict_to_verbs=True)\n",
    "f1_stanza_tense_verbs = macro_f1_tense(df, \"stanza_tense\", restrict_to_verbs=True)\n",
    "gap_tense_verbs = f1_stanza_tense_verbs - f1_spacy_tense_verbs\n",
    "\n",
    "print(f\"spaCy Tense F1 (VERB only):   {f1_spacy_tense_verbs:.3f}\")\n",
    "print(f\"Stanza Tense F1 (VERB only):  {f1_stanza_tense_verbs:.3f}\")\n",
    "print(f\"Tense gap (VERB only):        {gap_tense_verbs:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c79ee5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy Tense F1 (has gold Tense):   0.729\n",
      "Stanza Tense F1 (has gold Tense):  0.708\n",
      "Tense gap (has gold Tense):        -2.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zz/9j6cqjd91k7190vj479mr1jw0000gn/T/ipykernel_9536/2265161707.py:50: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(series):\n",
      "/var/folders/zz/9j6cqjd91k7190vj479mr1jw0000gn/T/ipykernel_9536/2265161707.py:50: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(series):\n",
      "/var/folders/zz/9j6cqjd91k7190vj479mr1jw0000gn/T/ipykernel_9536/2265161707.py:50: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(series):\n",
      "/var/folders/zz/9j6cqjd91k7190vj479mr1jw0000gn/T/ipykernel_9536/2265161707.py:50: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(series):\n"
     ]
    }
   ],
   "source": [
    "mask_has_tense = df[\"gold_tense\"].notna()\n",
    "f1_spacy_tense_all  = macro_f1_tense(df[mask_has_tense], \"spacy_tense\",  restrict_to_verbs=False)\n",
    "f1_stanza_tense_all = macro_f1_tense(df[mask_has_tense], \"stanza_tense\", restrict_to_verbs=False)\n",
    "gap_tense_all = f1_stanza_tense_all - f1_spacy_tense_all\n",
    "\n",
    "print(f\"spaCy Tense F1 (has gold Tense):   {f1_spacy_tense_all:.3f}\")\n",
    "print(f\"Stanza Tense F1 (has gold Tense):  {f1_stanza_tense_all:.3f}\")\n",
    "print(f\"Tense gap (has gold Tense):        {gap_tense_all:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b930a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.98      0.95      0.96      1043\n",
      "         ADP       0.99      0.99      0.99       928\n",
      "         ADV       0.94      0.93      0.94       533\n",
      "         AUX       0.98      0.97      0.98       122\n",
      "       CCONJ       0.98      0.98      0.98       322\n",
      "         DET       0.96      0.99      0.98       440\n",
      "        NOUN       0.98      0.99      0.99      2721\n",
      "        PRON       0.99      0.97      0.98       563\n",
      "       PROPN       0.96      0.93      0.95       379\n",
      "        VERB       0.98      1.00      0.99      1207\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      8258\n",
      "   macro avg       0.98      0.97      0.97      8258\n",
      "weighted avg       0.98      0.98      0.98      8258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df[\"gold_upos\"].astype(str),\n",
    "                            df[\"spacy_upos\"].astype(str),\n",
    "                            labels=upos10, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6671d972",
   "metadata": {},
   "source": [
    "## train file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8a9a2e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>text</th>\n",
       "      <th>token_id</th>\n",
       "      <th>form</th>\n",
       "      <th>lemma</th>\n",
       "      <th>gold_upos</th>\n",
       "      <th>gold_xpos</th>\n",
       "      <th>gold_feats</th>\n",
       "      <th>gold_tense</th>\n",
       "      <th>head</th>\n",
       "      <th>deprel</th>\n",
       "      <th>space_after</th>\n",
       "      <th>char_start</th>\n",
       "      <th>char_end</th>\n",
       "      <th>spacy_upos</th>\n",
       "      <th>spacy_feats</th>\n",
       "      <th>spacy_tense</th>\n",
       "      <th>stanza_upos</th>\n",
       "      <th>stanza_feats</th>\n",
       "      <th>stanza_tense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ParlaMint-UA_2003-10-14-m0.u1.p1.lang1.s1</td>\n",
       "      <td>Доброго ранку, шановні народні депутати, запро...</td>\n",
       "      <td>1</td>\n",
       "      <td>Доброго</td>\n",
       "      <td>добрий</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>{'Case': 'Gen', 'Degree': 'Pos', 'Gender': 'Ma...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>amod</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ParlaMint-UA_2003-10-14-m0.u1.p1.lang1.s1</td>\n",
       "      <td>Доброго ранку, шановні народні депутати, запро...</td>\n",
       "      <td>2</td>\n",
       "      <td>ранку</td>\n",
       "      <td>ранок</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>{'Animacy': 'Inan', 'Case': 'Gen', 'Gender': '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ParlaMint-UA_2003-10-14-m0.u1.p1.lang1.s1</td>\n",
       "      <td>Доброго ранку, шановні народні депутати, запро...</td>\n",
       "      <td>3</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>punct</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ParlaMint-UA_2003-10-14-m0.u1.p1.lang1.s1</td>\n",
       "      <td>Доброго ранку, шановні народні депутати, запро...</td>\n",
       "      <td>4</td>\n",
       "      <td>шановні</td>\n",
       "      <td>шановний</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>{'Case': 'Voc', 'Degree': 'Pos', 'Number': 'Pl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>amod</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ParlaMint-UA_2003-10-14-m0.u1.p1.lang1.s1</td>\n",
       "      <td>Доброго ранку, шановні народні депутати, запро...</td>\n",
       "      <td>5</td>\n",
       "      <td>народні</td>\n",
       "      <td>народний</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>{'Case': 'Voc', 'Number': 'Plur'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>amod</td>\n",
       "      <td>True</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     sent_id  \\\n",
       "0  ParlaMint-UA_2003-10-14-m0.u1.p1.lang1.s1   \n",
       "1  ParlaMint-UA_2003-10-14-m0.u1.p1.lang1.s1   \n",
       "2  ParlaMint-UA_2003-10-14-m0.u1.p1.lang1.s1   \n",
       "3  ParlaMint-UA_2003-10-14-m0.u1.p1.lang1.s1   \n",
       "4  ParlaMint-UA_2003-10-14-m0.u1.p1.lang1.s1   \n",
       "\n",
       "                                                text  token_id     form  \\\n",
       "0  Доброго ранку, шановні народні депутати, запро...         1  Доброго   \n",
       "1  Доброго ранку, шановні народні депутати, запро...         2    ранку   \n",
       "2  Доброго ранку, шановні народні депутати, запро...         3        ,   \n",
       "3  Доброго ранку, шановні народні депутати, запро...         4  шановні   \n",
       "4  Доброго ранку, шановні народні депутати, запро...         5  народні   \n",
       "\n",
       "      lemma gold_upos gold_xpos  \\\n",
       "0    добрий       ADJ       ADJ   \n",
       "1     ранок      NOUN      NOUN   \n",
       "2         ,     PUNCT     PUNCT   \n",
       "3  шановний       ADJ       ADJ   \n",
       "4  народний       ADJ       ADJ   \n",
       "\n",
       "                                          gold_feats gold_tense  head deprel  \\\n",
       "0  {'Case': 'Gen', 'Degree': 'Pos', 'Gender': 'Ma...        NaN     2   amod   \n",
       "1  {'Animacy': 'Inan', 'Case': 'Gen', 'Gender': '...        NaN     0   root   \n",
       "2                                                 {}        NaN     6  punct   \n",
       "3  {'Case': 'Voc', 'Degree': 'Pos', 'Number': 'Pl...        NaN     6   amod   \n",
       "4                  {'Case': 'Voc', 'Number': 'Plur'}        NaN     6   amod   \n",
       "\n",
       "   space_after  char_start  char_end spacy_upos spacy_feats spacy_tense  \\\n",
       "0         True           0         7       None        None        None   \n",
       "1        False           8        13       None        None        None   \n",
       "2         True          13        14       None        None        None   \n",
       "3         True          15        22       None        None        None   \n",
       "4         True          23        30       None        None        None   \n",
       "\n",
       "  stanza_upos stanza_feats stanza_tense  \n",
       "0        None         None         None  \n",
       "1        None         None         None  \n",
       "2        None         None         None  \n",
       "3        None         None         None  \n",
       "4        None         None         None  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/UniversalDependencies/UD_Ukrainian-ParlaMint/master/uk_parlamint-ud-train.conllu\"\n",
    "df = read_ud_conllu(url)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7fa92a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eda37008e834627b57241493e9649d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-10 00:11:12 INFO: Downloaded file to /Users/pelmeshek1706/stanza_resources/resources.json\n",
      "2025-08-10 00:11:12 INFO: Downloading default packages for language: uk (Ukrainian) ...\n",
      "2025-08-10 00:11:13 INFO: File exists: /Users/pelmeshek1706/stanza_resources/uk/default.zip\n",
      "2025-08-10 00:11:15 INFO: Finished downloading models and saved to /Users/pelmeshek1706/stanza_resources\n",
      "2025-08-10 00:11:15 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4a62310f75447329b0641e7438e8df2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-10 00:11:15 INFO: Downloaded file to /Users/pelmeshek1706/stanza_resources/resources.json\n",
      "2025-08-10 00:11:15 INFO: Loading these models for language: uk (Ukrainian):\n",
      "===========================\n",
      "| Processor | Package     |\n",
      "---------------------------\n",
      "| tokenize  | iu          |\n",
      "| mwt       | iu          |\n",
      "| pos       | iu_charlm   |\n",
      "| lemma     | iu_nocharlm |\n",
      "===========================\n",
      "\n",
      "2025-08-10 00:11:15 INFO: Using device: cpu\n",
      "2025-08-10 00:11:15 INFO: Loading: tokenize\n",
      "2025-08-10 00:11:15 INFO: Loading: mwt\n",
      "2025-08-10 00:11:15 INFO: Loading: pos\n",
      "2025-08-10 00:11:16 INFO: Loading: lemma\n",
      "2025-08-10 00:11:17 INFO: Done loading processors!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>text</th>\n",
       "      <th>token_id</th>\n",
       "      <th>form</th>\n",
       "      <th>lemma</th>\n",
       "      <th>gold_upos</th>\n",
       "      <th>gold_xpos</th>\n",
       "      <th>gold_feats</th>\n",
       "      <th>gold_tense</th>\n",
       "      <th>head</th>\n",
       "      <th>deprel</th>\n",
       "      <th>space_after</th>\n",
       "      <th>char_start</th>\n",
       "      <th>char_end</th>\n",
       "      <th>spacy_upos</th>\n",
       "      <th>spacy_feats</th>\n",
       "      <th>spacy_tense</th>\n",
       "      <th>stanza_upos</th>\n",
       "      <th>stanza_feats</th>\n",
       "      <th>stanza_tense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ParlaMint-UA_2003-10-14-m0.u1.p1.lang1.s1</td>\n",
       "      <td>Доброго ранку, шановні народні депутати, запро...</td>\n",
       "      <td>1</td>\n",
       "      <td>Доброго</td>\n",
       "      <td>добрий</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>{'Case': 'Gen', 'Degree': 'Pos', 'Gender': 'Ma...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>amod</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ParlaMint-UA_2003-10-14-m0.u1.p1.lang1.s1</td>\n",
       "      <td>Доброго ранку, шановні народні депутати, запро...</td>\n",
       "      <td>2</td>\n",
       "      <td>ранку</td>\n",
       "      <td>ранок</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>{'Animacy': 'Inan', 'Case': 'Gen', 'Gender': '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ParlaMint-UA_2003-10-14-m0.u1.p1.lang1.s1</td>\n",
       "      <td>Доброго ранку, шановні народні депутати, запро...</td>\n",
       "      <td>3</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>punct</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ParlaMint-UA_2003-10-14-m0.u1.p1.lang1.s1</td>\n",
       "      <td>Доброго ранку, шановні народні депутати, запро...</td>\n",
       "      <td>4</td>\n",
       "      <td>шановні</td>\n",
       "      <td>шановний</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>{'Case': 'Voc', 'Degree': 'Pos', 'Number': 'Pl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>amod</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ParlaMint-UA_2003-10-14-m0.u1.p1.lang1.s1</td>\n",
       "      <td>Доброго ранку, шановні народні депутати, запро...</td>\n",
       "      <td>5</td>\n",
       "      <td>народні</td>\n",
       "      <td>народний</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>{'Case': 'Voc', 'Number': 'Plur'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>amod</td>\n",
       "      <td>True</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     sent_id  \\\n",
       "0  ParlaMint-UA_2003-10-14-m0.u1.p1.lang1.s1   \n",
       "1  ParlaMint-UA_2003-10-14-m0.u1.p1.lang1.s1   \n",
       "2  ParlaMint-UA_2003-10-14-m0.u1.p1.lang1.s1   \n",
       "3  ParlaMint-UA_2003-10-14-m0.u1.p1.lang1.s1   \n",
       "4  ParlaMint-UA_2003-10-14-m0.u1.p1.lang1.s1   \n",
       "\n",
       "                                                text  token_id     form  \\\n",
       "0  Доброго ранку, шановні народні депутати, запро...         1  Доброго   \n",
       "1  Доброго ранку, шановні народні депутати, запро...         2    ранку   \n",
       "2  Доброго ранку, шановні народні депутати, запро...         3        ,   \n",
       "3  Доброго ранку, шановні народні депутати, запро...         4  шановні   \n",
       "4  Доброго ранку, шановні народні депутати, запро...         5  народні   \n",
       "\n",
       "      lemma gold_upos gold_xpos  \\\n",
       "0    добрий       ADJ       ADJ   \n",
       "1     ранок      NOUN      NOUN   \n",
       "2         ,     PUNCT     PUNCT   \n",
       "3  шановний       ADJ       ADJ   \n",
       "4  народний       ADJ       ADJ   \n",
       "\n",
       "                                          gold_feats gold_tense  head deprel  \\\n",
       "0  {'Case': 'Gen', 'Degree': 'Pos', 'Gender': 'Ma...        NaN     2   amod   \n",
       "1  {'Animacy': 'Inan', 'Case': 'Gen', 'Gender': '...        NaN     0   root   \n",
       "2                                                 {}        NaN     6  punct   \n",
       "3  {'Case': 'Voc', 'Degree': 'Pos', 'Number': 'Pl...        NaN     6   amod   \n",
       "4                  {'Case': 'Voc', 'Number': 'Plur'}        NaN     6   amod   \n",
       "\n",
       "   space_after  char_start  char_end spacy_upos spacy_feats spacy_tense  \\\n",
       "0         True           0         7        ADJ        None         NaN   \n",
       "1        False           8        13       NOUN        None         NaN   \n",
       "2         True          13        14      PUNCT        None         NaN   \n",
       "3         True          15        22        ADJ        None         NaN   \n",
       "4         True          23        30        ADJ        None         NaN   \n",
       "\n",
       "  stanza_upos stanza_feats stanza_tense  \n",
       "0         ADJ         None          NaN  \n",
       "1        NOUN         None          NaN  \n",
       "2       PUNCT         None          NaN  \n",
       "3         ADJ         None          NaN  \n",
       "4         ADJ         None          NaN  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = run_spacy_and_attach(df, model_name=\"uk_core_news_md\")\n",
    "df = run_stanza_and_attach(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "374c4daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy UPOS F1: 0.974\n",
      "Stanza UPOS F1: 0.974\n",
      "GAP: 0.071%\n"
     ]
    }
   ],
   "source": [
    "upos10 = [\"ADJ\",\"ADP\",\"ADV\",\"AUX\",\"CCONJ\",\"DET\",\"NOUN\",\"PRON\",\"PROPN\",\"VERB\"]\n",
    "\n",
    "f1_spacy_upos = macro_f1(df, \"gold_upos\", \"spacy_upos\", labels=upos10)\n",
    "f1_stanza_upos = macro_f1(df, \"gold_upos\", \"stanza_upos\", labels=upos10)\n",
    "gap = f1_stanza_upos - f1_spacy_upos\n",
    "\n",
    "print(f\"spaCy UPOS F1: {f1_spacy_upos:.3f}\")\n",
    "print(f\"Stanza UPOS F1: {f1_stanza_upos:.3f}\")\n",
    "print(f\"GAP: {gap:.3%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4b97e0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy Tense F1 (VERB only):   0.967\n",
      "Stanza Tense F1 (VERB only):  0.952\n",
      "Tense gap (VERB only):        -1.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zz/9j6cqjd91k7190vj479mr1jw0000gn/T/ipykernel_9536/2265161707.py:50: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(series):\n",
      "/var/folders/zz/9j6cqjd91k7190vj479mr1jw0000gn/T/ipykernel_9536/2265161707.py:50: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(series):\n",
      "/var/folders/zz/9j6cqjd91k7190vj479mr1jw0000gn/T/ipykernel_9536/2265161707.py:50: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(series):\n",
      "/var/folders/zz/9j6cqjd91k7190vj479mr1jw0000gn/T/ipykernel_9536/2265161707.py:50: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(series):\n"
     ]
    }
   ],
   "source": [
    "f1_spacy_tense_verbs  = macro_f1_tense(df, \"spacy_tense\",  restrict_to_verbs=True)\n",
    "f1_stanza_tense_verbs = macro_f1_tense(df, \"stanza_tense\", restrict_to_verbs=True)\n",
    "gap_tense_verbs = f1_stanza_tense_verbs - f1_spacy_tense_verbs\n",
    "\n",
    "print(f\"spaCy Tense F1 (VERB only):   {f1_spacy_tense_verbs:.3f}\")\n",
    "print(f\"Stanza Tense F1 (VERB only):  {f1_stanza_tense_verbs:.3f}\")\n",
    "print(f\"Tense gap (VERB only):        {gap_tense_verbs:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "63b127f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy Tense F1 (has gold Tense):   0.731\n",
      "Stanza Tense F1 (has gold Tense):  0.719\n",
      "Tense gap (has gold Tense):        -1.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zz/9j6cqjd91k7190vj479mr1jw0000gn/T/ipykernel_9536/2265161707.py:50: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(series):\n",
      "/var/folders/zz/9j6cqjd91k7190vj479mr1jw0000gn/T/ipykernel_9536/2265161707.py:50: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(series):\n",
      "/var/folders/zz/9j6cqjd91k7190vj479mr1jw0000gn/T/ipykernel_9536/2265161707.py:50: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(series):\n",
      "/var/folders/zz/9j6cqjd91k7190vj479mr1jw0000gn/T/ipykernel_9536/2265161707.py:50: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(series):\n"
     ]
    }
   ],
   "source": [
    "mask_has_tense = df[\"gold_tense\"].notna()\n",
    "f1_spacy_tense_all  = macro_f1_tense(df[mask_has_tense], \"spacy_tense\",  restrict_to_verbs=False)\n",
    "f1_stanza_tense_all = macro_f1_tense(df[mask_has_tense], \"stanza_tense\", restrict_to_verbs=False)\n",
    "gap_tense_all = f1_stanza_tense_all - f1_spacy_tense_all\n",
    "\n",
    "print(f\"spaCy Tense F1 (has gold Tense):   {f1_spacy_tense_all:.3f}\")\n",
    "print(f\"Stanza Tense F1 (has gold Tense):  {f1_stanza_tense_all:.3f}\")\n",
    "print(f\"Tense gap (has gold Tense):        {gap_tense_all:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ad13c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.98      0.99      0.98      6649\n",
      "         ADP       1.00      1.00      1.00      5440\n",
      "         ADV       0.95      0.94      0.95      3188\n",
      "         AUX       0.95      0.95      0.95       623\n",
      "       CCONJ       0.98      0.98      0.98      2254\n",
      "         DET       0.96      0.99      0.97      2676\n",
      "        NOUN       0.98      0.99      0.98     16050\n",
      "        PRON       0.98      0.97      0.98      3117\n",
      "       PROPN       0.95      0.96      0.95      2191\n",
      "        VERB       0.98      0.99      0.99      6543\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     48731\n",
      "   macro avg       0.97      0.98      0.97     48731\n",
      "weighted avg       0.98      0.98      0.98     48731\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df[\"gold_upos\"].astype(str),\n",
    "                            df[\"spacy_upos\"].astype(str),\n",
    "                            labels=upos10, zero_division=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd_311_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
